# ğŸ¨ Neural Style Transfer Using CNN ğŸ§ ğŸ–¼ï¸

Welcome to the **Neural Style Transfer** project! This repository showcases a powerful computer vision technique using Convolutional Neural Networks (CNNs) to transform a content image with the artistic style of another image. The implementation uses TensorFlow and a pre-trained model from TensorFlow Hub to stylize images in real time.

---

## ğŸ“‹ Table of Contents

* Project Description
* Requirements
* Week 1 Overview
* Week 2 Overview
* Week 3 Overview
* How to Run the Project
* Output Example
* License

---

## ğŸ“ Project Description

This project implements Neural Style Transfer using a model trained on millions of images to extract content and style features. By leveraging deep layers of VGG19 and style/content loss functions, it stylizes one image (content) using the artistic elements of another (style). Applications include creative design, photo enhancement, and real-time art filters.

The model can be run on local machines or Google Colab, and produces fast, high-quality results without retraining.

---

## ğŸ§  Key Features

* **Fast Arbitrary Image Stylization** using TensorFlow Hub.
* **Content/Style Feature Extraction** using VGG19 CNN layers.
* **No Retraining Required** â€“ supports any content and style image pair.
* **Easily Extendable** â€“ batch processing, UI integration, or app deployment.

---

## ğŸ§° Requirements

To run this project, youâ€™ll need:

* Python 3
* TensorFlow
* TensorFlow Hub
* NumPy
* Pillow (PIL)
* Matplotlib
* Google Colab (optional, for cloud execution)

Install dependencies:

```bash
pip install -r requirements.txt
```

**requirements.txt**

```
tensorflow
tensorflow-hub
numpy
pillow
matplotlib
```

---

## ğŸ“… Week 1 Overview

**What was done:**

* Loaded and preprocessed content and style images ğŸ–¼ï¸
* Loaded a pre-trained style transfer model from TensorFlow Hub âš™ï¸
* Implemented image resizing, normalization, and formatting

**Goals:**

* Understand neural style transfer pipeline
* Setup image transformation functions

---

## ğŸ—“ï¸ Week 2: Stylization Execution & Enhancements

**Improvements:**

* Stylized image generation with various content/style pairs
* Added matplotlib-based visualization of input and result images
* Optimized image tensor conversion pipeline

---

## ğŸ“ˆ Week 3: Output Saving & Experimentation

**Enhancements:**

* Saved stylized images automatically to output folder
* Batch stylization supported by looping over multiple content images
* Refactored notebook structure for modular reuse

---

## âš™ï¸ How to Run the Project

1. Clone the repo:

```bash
git clone https://github.com/yourname/neural-style-transfer-cnn.git
```

2. Upload your content/style images to the appropriate folders:

```
content/
style/
```

3. Run the notebook:

```bash
notebooks/fast_style_transfer.ipynb
```

4. Output image will be saved in:

```
output/
```

---

## ğŸ–¼ï¸ Output Example

```
output/
â”œâ”€â”€ stylized_output.jpg   # Final stylized image
```

Example visual: Left - Content | Middle - Style | Right - Stylized Result ğŸ¨

To improve this section, include sample images:

* ğŸ“· Realistic photo (e.g., portrait, cityscape)
* ğŸ–Œï¸ Artistic image (Van Gogh, Picasso, etc.)
* ğŸ¨ Stylized result image

---

## ğŸ“ License

This project is open-source under the MIT License.

---

## ğŸ¤– Contributions

Pull requests, ideas, and issues are welcome. Help expand it with better models, mobile support, or deployment tools!

---

## ğŸ‘¤ Author

Your Shaili Sahu Here
âœ‰ï¸ Email: [shailisahu283@gmail.com](shailisahu283@gmail.com)
